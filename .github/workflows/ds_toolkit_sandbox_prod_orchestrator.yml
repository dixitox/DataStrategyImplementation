name: DS-Toolkit-Sandbox-Prod-Orchestrator
run-name: DS-Toolkit deploying ||${{ inputs.repositoryName }}|| 

on: 
  workflow_dispatch:
    inputs:
      repositoryName:
        required: false
      repositoryUrl:
        required: false
      environment:
        required: false
  
# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:

  cloneDSToolkit: #job1

      # The type of runner that the job will run on
      runs-on: ubuntu-22.04
      if: ${{ github.event.inputs.environment == 'sandbox' }}
      steps:

        - name: Clone Repo Locally
          run: |
            gh repo clone ${{ github.event.inputs.repositoryUrl }} 
          env:
            GH_TOKEN: ${{ secrets.ACCESS_TOKEN }}

        - name: Create New Repository 
          run: |
            gh repo create ${{ github.event.inputs.repositoryName }}-${{ github.event.inputs.environment }} --private --clone
          env:
            GITHUB_TOKEN: ${{ secrets.ACCESS_TOKEN }}

        - name: Clone first repo into second repo
          run: |
            pwd 
            ls
            cd ${{ github.event.inputs.repositoryName }}-${{ github.event.inputs.environment }}
            git status
            echo "--------------------------------------------------------------"
            git branch -M main
            git status
            echo "--------------------------------------------------------------"
            cd ..
            Copy-Item -Path ".\${{ github.event.inputs.repositoryName }}\*" -Destination ".\${{ github.event.inputs.repositoryName }}-${{ github.event.inputs.environment }}" -Recurse
            cd ${{ github.event.inputs.repositoryName }}-${{ github.event.inputs.environment }}
            echo "--------------------------------------------------------------"
            ls
            git config --global user.name ${{ secrets.USER_NAME }}
            git config --global user.email ${{ secrets.USER_EMAIL }}
            git remote set-url origin https://x-access-token:${{ secrets.ACCESS_TOKEN }}@github.com/${{ github.repository_owner }}/${{ github.event.inputs.repositoryName }}-${{ github.event.inputs.environment }}
            echo "--------------------------------------------------------------"
            ls
            git status
            git add .
            git commit -m "Clone first repo into second repo"
            git push --set-upstream origin main 
          shell: pwsh

  get-env-variables: #job2

    needs: cloneDSToolkit
    if: ${{ github.event.inputs.environment == 'sandbox' }}

    # The type of runner that the job will run on
    runs-on: ubuntu-22.04

    outputs:
      DeployDevEnvironment: ${{ env.DeployDevEnvironment }}      

    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v3

      - name: Determine Environments to Deploy 
        run: |
          $ff_dev = Get-Content "./DeliveryIP_GitHub/variables/general_feature_flags/feature_flags_dev.json" | ConvertFrom-Json -AsHashtable
          $DeployDevEnvironment = $ff_dev.DeployDevEnvironment
          "DeployDevEnvironment=$DeployDevEnvironment" >> $env:GITHUB_ENV
        shell: pwsh

  deploy-dev-azure-resources: #job3
    needs: get-env-variables
    if: ${{ (needs.get-env-variables.outputs.DeployDevEnvironment == 'True') && (github.event.inputs.environment == 'sandbox')}}
    uses: ./.github/workflows/deployment_environment.yml
    with:
      environment: 'development'
      envFolderPath: 'dev'
    secrets:
      SUBSCRIPTION_ID: ${{ secrets.SUBSCRIPTION_ID_DEV }}
      TENANT_ID: ${{ secrets.TENANT_ID }}
      SERVICE_PRINCIPAL_CLIENT_ID: ${{ secrets.SERVICE_PRINCIPAL_CLIENT_ID }}

  deployToProd: #job5
    if: ${{ github.event.inputs.environment == 'production' }}
    runs-on: ubuntu-22.04

    steps:
    
      # Checkout the model repository
      - name: Checkout model repository
        uses: actions/checkout@v3
        with:
          repository: ${{ github.repository_owner }}/${{ github.event.inputs.repositoryName }}-sandbox
          token: ${{ secrets.ACCESS_TOKEN }}
          path: model_repo
      
      # Checkout the target repo
      - name: Checkout production repository
        uses: actions/checkout@v3
        with:
          repository: ${{ github.repository_owner }}/${{ github.event.inputs.repositoryName }}-production
          token: ${{ secrets.ACCESS_TOKEN }}
          path: prod_repo
      
      # Copying Files over from the model repo to the target (prod) repo
      - name: Copy Files and Commit Changes
        run: |
            pwd 
            ls
            Copy-Item -Path ".\model_repo\*" -Destination ".\prod_repo" -Recurse
            cd prod_repo
            git config --global user.name ${{ secrets.USER_NAME }}
            git config --global user.email ${{ secrets.USER_EMAIL }}
            git remote set-url origin https://x-access-token:${{ secrets.ACCESS_TOKEN }}@github.com/${{ github.repository_owner }}/${{ github.event.inputs.repositoryName }}-production
            git status
            git add .
            git commit -m "Deployed Model into Production"
            git push --set-upstream origin main 
        shell: pwsh
        
  deploy-mlops-artifacts:
      needs: deployToProd
      if: ${{ github.event.inputs.environment == 'production' }}
  
      # The type of runner that the job will run on
      runs-on: ubuntu-22.04

      # Steps represent a sequence of tasks that will be executed as part of the job
      steps:
        # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
        - uses: actions/checkout@v3

        # Log into Azure
        - name: Azure CLI login
          uses: azure/login@v1
          with:
            creds: '{"clientId": "${{ secrets.SERVICE_PRINCIPAL_CLIENT_ID }}", "clientSecret": "${{ secrets.SERVICE_PRINCIPAL_SECRET }}", "subscriptionId": "${{ secrets.SUBSCRIPTION_ID_DEV }}", "tenantId": "${{ secrets.TENANT_ID }}"}'
            enable-AzPSSession: true

        # Using the Variables for the dev environment
        - name: Get Main Variables 
          run: |
            $json_data = Get-Content "./DeliveryIP_GitHub/variables/general_variables/variables_prod.json" | ConvertFrom-Json -AsHashtable
            foreach ( $item in $json_data.GetEnumerator() )
            {
              if($($item.Value).GetType().Name -eq "Hashtable"){
                $value = $($item.Value) | ConvertTo-Json -Compress
                "$($item.Name)=$value" >> $env:GITHUB_ENV
              } else {
                "$($item.Name)=$($item.Value)" >> $env:GITHUB_ENV
              }
            }
          shell: pwsh

        - name: Configure Python
          uses: actions/setup-python@v2
          with:
            python-version: '3.8'

        - name: Install dependencies for tabular data
          run: pip install -r DeliveryIP_GitHub/mlops_artifacts/tabular_config_scripts/requirements.txt

        # Install Dependencies for pdf data
        - name: Install dependencies for pdf data
          run: pip install -r DeliveryIP_GitHub/mlops_artifacts/pdf_config_scripts/requirements.txt
          
        - name: Create Containers in Datalake
          uses: azure/powershell@v1
          with:
            inlineScript: |
              Select-AzSubscription -SubscriptionName ${{ env.subscriptionName }}
              az storage fs create -n serve --account-name ${{ env.dataLakeName }} --auth-mode login
              az storage fs create -n data-processed --account-name ${{ env.dataLakeName }} --auth-mode login
              az storage fs create -n ml-processed --account-name ${{ env.dataLakeName }} --auth-mode login
              az storage fs create -n staging --account-name ${{env.dataLakeName }} --auth-mode login
              az storage fs create -n ml-pipeline-intermediate --account-name ${{ env.dataLakeName }} --auth-mode login
            azPSVersion: "latest"  

        # Create ML Artifacts
        - name: Create ML Artifacts
          run: python DeliveryIP_GitHub/mlops_artifacts/ml_scripts/ml_artifacts_script.py --ws_name ${{ env.mlWorkspaceName }} --amls_rg ${{ env.MlRgName }} --client_id ${{ secrets.SERVICE_PRINCIPAL_CLIENT_ID }} --client_secret ${{ secrets.SERVICE_PRINCIPAL_SECRET }} --tenant_id ${{ secrets.TENANT_ID }} --sub_id ${{ secrets.SUBSCRIPTION_ID_DEV }} --adls_rg ${{ env.PrimaryRgName }} --adls_name ${{ env.dataLakeName }} --cluster_name ${{ env.mlComputeName }}

        # Create Synapse ACTS ML Pipeline
        - name: Create Synapse ACTS ML Pipeline
          uses: azure/powershell@v1 
          with:
              inlineScript: |
                Install-Module Az.Synapse -Repository PSGallery -Force
                Select-AzSubscription -SubscriptionName ${{ env.subscriptionName }}
                Set-AzSynapseDataset -WorkspaceName ${{ env.synapseWorkspaceName }} -Name 'DS_ADLS_VAT_Tax_Daily_Score' -DefinitionFile './DeliveryIP_GitHub/synapse_adf_artifacts/integration_datasets/DS_ADLS_VAT_Tax_Daily_Score.json'
                Set-AzSynapseDataset -WorkspaceName ${{ env.synapseWorkspaceName }} -Name 'DS_ADLS_VAT_Tax_Serve' -DefinitionFile './DeliveryIP_GitHub/synapse_adf_artifacts/integration_datasets/DS_ADLS_VAT_Tax_Serve.json'
                Set-AzSynapseNotebook -WorkspaceName ${{ env.synapseWorkspaceName }} -Name 'data-drift' -DefinitionFile './DeliveryIP_GitHub/synapse_adf_artifacts/notebooks/data-drift.ipynb'
                Set-AzSynapseNotebook -WorkspaceName ${{ env.synapseWorkspaceName }} -Name 'data-processing' -DefinitionFile './DeliveryIP_GitHub/synapse_adf_artifacts/notebooks/data-processing.ipynb'
                Set-AzSynapseDataFlow -WorkspaceName ${{ env.synapseWorkspaceName }} -Name 'df_VATDaily' -DefinitionFile './DeliveryIP_GitHub/synapse_adf_artifacts/dataflows/df_VATDaily.json'
                Set-AzSynapsePipeline -WorkspaceName ${{ env.synapseWorkspaceName }} -Name 'PL_Synapse_Ml_Pipeline' -DefinitionFile './DeliveryIP_GitHub/synapse_adf_artifacts/pipelines/PL_Synapse_Ml_Pipeline.json'
              azPSVersion: 9.4.0

        # Deploying the AML model
        - name: Deploy AML Model to ACI
          run: python DeliveryIP_GitHub/mlops_artifacts/ml_scripts/deploy_aci.py --subscription_id ${{ secrets.SUBSCRIPTION_ID_DEV }} --tenant_id ${{ secrets.TENANT_ID }} --client_id ${{ secrets.SERVICE_PRINCIPAL_CLIENT_ID }} --client_secret ${{ secrets.SERVICE_PRINCIPAL_SECRET }} --resource_group ${{ env.MlRgName }} --workspace_name ${{ env.mlWorkspaceName }}

        # Replacing the variables for the 
        - name: Replace Variables
          uses: azure/powershell@v1
          with:
            inlineScript: |
              $filepaths = (
              "${{ github.workspace }}/DeliveryIP_GitHub/mlops_artifacts/config_scripts/constants_in_common.py"
              );

              $variables = @{
              "__subid__" = "${{ secrets.SUBSCRIPTION_ID_DEV }}";
              "__mlrg__" = "${{ env.MlRgName }}";
              "__amlskv__" = "${{ env.mlWorkspaceKeyVaultName }}";
              "__tenantid__" = "${{ secrets.TENANT_ID }}";
              "__amlswksp__" = "${{ env.mlWorkspaceName }}";
              "__cluster__" = "${{ env.mlComputeName }}"
              };

              #Replace Variables in File
              foreach ($file in $filepaths){
                  $content = (Get-Content $file);
                  foreach ($key in $variables.Keys){
                      $content = $content.Replace($key,$variables[$key]);
                  }
                  Set-Content -Path $file -Value $content;
              }
            azPSVersion: "9.5.0"

        # Publishing the aml pipeline
        - name: Publish AML Pipeline
          run: |
            python DeliveryIP_GitHub/mlops_artifacts/ml_scripts/publish_aml_pipeline.py --client_id ${{ secrets.SERVICE_PRINCIPAL_CLIENT_ID }} --client_secret ${{ secrets.SERVICE_PRINCIPAL_SECRET }} --resource_group ${{ env.MlRgName }} --subscription_id ${{ secrets.SUBSCRIPTION_ID_DEV }} --tenant_id ${{ secrets.TENANT_ID }} --workspace_name ${{ env.mlWorkspaceName }} --define_pipeline 1 --draft_endpoint 0
