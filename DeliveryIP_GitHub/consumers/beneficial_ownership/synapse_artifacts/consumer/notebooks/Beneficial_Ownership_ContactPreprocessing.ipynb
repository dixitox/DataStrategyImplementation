{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "import re\r\n",
        "import pyspark.sql.functions as F\r\n",
        "from pyspark.sql.types import StringType, IntegerType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "def concat_address(column_values: list, join_token: str=' ') -> str:\r\n",
        "    \"\"\"\r\n",
        "    Concat multiple address fields into a single attribute\r\n",
        "    \"\"\"\r\n",
        "    compound_values = []\r\n",
        "    ret = ''\r\n",
        "    for value in column_values:\r\n",
        "        if value and (str(value)).strip().upper() != '':\r\n",
        "            value = re.sub(r'[_;\\s]+', ' ', re.sub(r'[.,():/]', '', str(value).upper())).strip()\r\n",
        "            compound_values.append(value)\r\n",
        "    if len(compound_values) > 0:\r\n",
        "        ret = join_token.join(compound_values)\r\n",
        "    return ret\r\n",
        "spark.udf.register(\"concat_address\", concat_address, StringType())\r\n",
        "\r\n",
        "def is_valid_phone_number(phone_number: str, min_length: int=7) -> int:\r\n",
        "    \"\"\"\r\n",
        "    Flag phone numbers that are too short, or contain single digits, e.g. 1111111, 11222222\r\n",
        "    \"\"\"\r\n",
        "    if len(phone_number) < min_length:\r\n",
        "        return 0\r\n",
        "    else:\r\n",
        "        # check if the phone number contains only single digits\r\n",
        "        if len(phone_number) <= 2:\r\n",
        "            digits = set(phone_number)\r\n",
        "        else:\r\n",
        "            # do not take into account first 2 digits which are likely area code\r\n",
        "            digits = set(phone_number[2:])\r\n",
        "        return 0 if len(digits) == 1 else 1\r\n",
        "spark.udf.register(\"is_valid_phone_number\", is_valid_phone_number, IntegerType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "'''\r\n",
        "Convert entity attribute data from wide format to long format.\r\n",
        "Input: \r\n",
        "- Attributes in wide format: [entity, attribute_1, attribute_2, ...]\r\n",
        "- attribute mappings: e.g.\r\n",
        "    \"contact_attribute_mapping\": {\r\n",
        "        \"name\": \r\n",
        "        {\r\n",
        "            \"mapping_cols\": [\"official_name\", \"commercial_name\"],\r\n",
        "            \"output_table\": \"company_names\"\r\n",
        "        },\r\n",
        "        \"address\": \r\n",
        "        {\r\n",
        "            \"mapping_cols\": [\"address\"],\r\n",
        "            \"output_table\": \"company_addresses\"\r\n",
        "        }\r\n",
        "    }\r\n",
        "Output: \r\n",
        "- Attribute data in long format: [entity, attribute, value]\r\n",
        "'''\r\n",
        "\r\n",
        "def convert_to_long_format(\r\n",
        "    attribute_wide_format_data: DataFrame,\r\n",
        "    attribute_mappings: dict,\r\n",
        "    entity_col: str = 'company', \r\n",
        "    time_col: str = None\r\n",
        ") -> DataFrame:\r\n",
        "    # get a list of contact attribute columns\r\n",
        "    attribute_columns = []\r\n",
        "    for attribute in attribute_mappings:\r\n",
        "        attribute_columns.extend(attribute_mappings[attribute]['mapping_cols'])\r\n",
        "\r\n",
        "    # load attribute data\r\n",
        "    if time_col is None:\r\n",
        "        attribute_wide_format_data = attribute_wide_format_data.select([entity_col] + attribute_columns)\r\n",
        "    else:\r\n",
        "        attribute_wide_format_data = attribute_wide_format_data.select([entity_col, time_col] + attribute_columns)\r\n",
        "\r\n",
        "    # convert contact data to long format\r\n",
        "    if time_col is None:\r\n",
        "        melted_attribute_data = melt(\r\n",
        "            data=attribute_wide_format_data,\r\n",
        "            id_vars=[entity_col],\r\n",
        "            value_vars=attribute_columns,\r\n",
        "            var_name='attribute',\r\n",
        "            value_name='value'\r\n",
        "        )\r\n",
        "    else:\r\n",
        "        melted_attribute_data = melt(\r\n",
        "            data=attribute_wide_format_data,\r\n",
        "            id_vars=[entity_col, time_col],\r\n",
        "            value_vars=attribute_columns,\r\n",
        "            var_name='attribute',\r\n",
        "            value_name='value'\r\n",
        "        )\r\n",
        "\r\n",
        "    melted_attribute_data = melted_attribute_data.filter(F.trim('value') != \"\")\r\n",
        "    return melted_attribute_data\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "\"\"\"\r\n",
        "Convert dataframe from wide format to long format. Equivalent to pd.melt\r\n",
        "Reference: https://stackoverflow.com/questions/41670103/how-to-melt-spark-dataframe\r\n",
        "\"\"\"\r\n",
        "def melt(\r\n",
        "        data: DataFrame, \r\n",
        "        id_vars: Iterable[str], \r\n",
        "        value_vars: Iterable[str], \r\n",
        "        var_name: str=\"attribute\", \r\n",
        "        value_name: str=\"value\") -> DataFrame:\r\n",
        "    var_value_pairs = F.create_map(\r\n",
        "        list(chain.from_iterable([\r\n",
        "            [F.lit(column), F.col(column)] for column in value_vars]\r\n",
        "        ))\r\n",
        "    )\r\n",
        "    \r\n",
        "    data = data.select(*id_vars, F.explode(var_value_pairs)) \\\r\n",
        "        .withColumnRenamed('key', var_name) \\\r\n",
        "        .withColumnRenamed('value', value_name)\r\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "contact_data = spark.sql(f\"\"\"\r\n",
        "    SELECT DISTINCT\r\n",
        "        {entity_col},\r\n",
        "        establishment,\r\n",
        "        establishment_type,\r\n",
        "        official_name,\r\n",
        "        commercial_name,\r\n",
        "        email,\r\n",
        "        phone_number,\r\n",
        "        is_valid_phone_number(phone_number) AS is_valid_phone,\r\n",
        "        TRIM(UPPER(concat_address(array(street_number, \r\n",
        "                                        street_name, \r\n",
        "                                        address_complement,\r\n",
        "                                        district, \r\n",
        "                                        city_name,\r\n",
        "                                        state, \r\n",
        "                                        zip_code), ' '))) AS address\r\n",
        "    FROM {output_db}.{input_table}\r\n",
        "    WHERE {entity_col} != '' \r\n",
        "    \"\"\").repartition(partitions)\r\n",
        "if display_data:\r\n",
        "    display(contact_data.limit(100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# set invalid phone numbers to empty string so we can filter them out later\r\n",
        "contact_data = contact_data.withColumn('phone_number', \r\n",
        "                                        F.when(F.col('is_valid_phone') == 0, '').otherwise(F.col('phone_number')))\r\n",
        "\r\n",
        "# minor cleanup on strings\r\n",
        "for attribute in attribute_columns:\r\n",
        "    contact_data = contact_data.withColumn(attribute, \r\n",
        "                                           F.regexp_replace(F.col(attribute), \"[\\\"\\'*()]\", \"\")) \r\n",
        "    contact_data = contact_data.withColumn(attribute, F.expr(f\"rtrim('.', rtrim({attribute}))\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "hq_contact_data = contact_data.filter(F.col('establishment_type') == 'headquarter').distinct()\r\n",
        "hq_contact_data = hq_contact_data.select([entity_col] + attribute_columns)\r\n",
        "for attribute in attribute_columns:\r\n",
        "    hq_contact_data = hq_contact_data.withColumnRenamed(attribute, f'headquarter_{attribute}')\r\n",
        "contact_data = contact_data.join(hq_contact_data, on='company', how='left').cache()\r\n",
        "contact_data = contact_data.drop(*['is_valid_phone', 'establishment'])\r\n",
        "\r\n",
        "print(f'Total records: {contact_data.count()}')\r\n",
        "print(f'Number of companies: {contact_data.select(entity_col).distinct().count()}')\r\n",
        "\r\n",
        "if display_data:\r\n",
        "    display(contact_data.limit(100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "melted_contact_data = convert_to_long_format(\r\n",
        "                        attribute_wide_format_data=contact_data,\r\n",
        "                        attribute_mappings=attribute_dict,\r\n",
        "                        entity_col=entity_col\r\n",
        "                    )"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "language_info": {
      "name": "python"
    }
  }
}